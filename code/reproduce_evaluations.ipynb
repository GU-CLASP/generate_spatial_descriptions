{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_dir = 'visual_genome/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silly_report(fn, msg):\n",
    "    s = time()\n",
    "    print('waiting for {0}'.format(msg), end='\\r')\n",
    "    out = fn()\n",
    "    print(' '*len('waiting for {0}'.format(msg)), end='\\r')\n",
    "    e = time()\n",
    "    print('{0} in {1:0.2f}s'.format(msg, e-s))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image names in 0.37s   \n",
      "loading relationships corpus in 32.24s  \n",
      "loading pre-processed image ids in 0.01s   \n",
      "preprocess rels into triplets+bbox in 10.80s  \n",
      "loading image visual features in 379.31s \n",
      "filtering relations in 0.30s   \n",
      "loading bbox visual features in 140.66s \n",
      "filtering relations in 0.20s   \n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://cs.stanford.edu/people/rak248/'\n",
    "\n",
    "images = None\n",
    "rels_from_file = None\n",
    "\n",
    "## read image data from files\n",
    "def load_images():\n",
    "    return {\n",
    "        item['image_id']: {\n",
    "            'width'  : item['width'],\n",
    "            'height' : item['height'],\n",
    "            'path'   : item['url'].replace(base_url, '{0}/')\n",
    "        }\n",
    "        for item in json.load(open('{0}/image_data.json'.format(vg_dir)))\n",
    "    }\n",
    "\n",
    "# read corpus from the file\n",
    "def load_rels():\n",
    "    return json.load(open('{0}/relationships.json'.format(vg_dir)))\n",
    "\n",
    "# retrieve pre-processed image ids\n",
    "def load_image_ids():\n",
    "    return list(np.load('{0}/relationships/image_ids.npy'.format(vg_dir)))\n",
    "\n",
    "# preprocess the relations into triplets and bbox\n",
    "def preprocess_rels():\n",
    "    # name/names correction for reading content of nodes in the dataset\n",
    "    def name_extract(x):\n",
    "        if 'names' in x and len(x['names']):\n",
    "            name = x['names'][0]\n",
    "        elif 'name' in x:\n",
    "            name = x['name']\n",
    "        else:\n",
    "            name = ''\n",
    "        return name.strip().lower()\n",
    "\n",
    "    # convert it into a set of (image, subject, predicate, object)\n",
    "    triplets_key_values = {\n",
    "        (\n",
    "            rels_in_image['image_id'],\n",
    "            name_extract(rel['subject']),\n",
    "            rel['predicate'].lower().strip(),\n",
    "            name_extract(rel['object']),\n",
    "        ): (\n",
    "            rels_in_image['image_id'],\n",
    "            (name_extract(rel['subject']), rel['subject']['object_id'], (rel['subject']['x'],rel['subject']['y'],rel['subject']['w'],rel['subject']['h'])),\n",
    "            rel['predicate'].lower().strip(),\n",
    "            (name_extract(rel['object']), rel['object']['object_id'], (rel['object']['x'], rel['object']['y'], rel['object']['w'], rel['object']['h'])),\n",
    "        )\n",
    "        for rels_in_image in rels_from_file\n",
    "        for rel in rels_in_image['relationships']\n",
    "    }\n",
    "    triplets = list(triplets_key_values.values())\n",
    "    del triplets_key_values\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "def load_img_vf():\n",
    "    #unseen_img_ids = list(np.load('visual_genome/data/relationships/image_ids_test.npy'))\n",
    "    train_img_ids = {\n",
    "        img_id\n",
    "        for img_id,_,_,_ in triplets[:int(0.95*len(triplets))]\n",
    "    }\n",
    "    valid_img_ids = {\n",
    "        img_id\n",
    "        for img_id,_,_,_ in triplets[int(0.95*len(triplets)):]\n",
    "    }\n",
    "    unseen_img_ids = valid_img_ids - train_img_ids\n",
    "    \n",
    "    chunck_size = 10000\n",
    "    img_visual_features = []\n",
    "    for l in range(0, len(image_ids), chunck_size):\n",
    "        vfs = np.load('{0}/relationships/image_resnet50_features_[{1}].npy'.format(vg_dir, l), allow_pickle=True)\n",
    "        img_visual_features += [\n",
    "            (iid, vf)\n",
    "            for iid, vf in zip(image_ids[l:l+chunck_size], vfs)\n",
    "            if iid in unseen_img_ids\n",
    "            if type(vf) != int\n",
    "        ]\n",
    "        del vfs\n",
    "\n",
    "    return dict(img_visual_features)\n",
    "\n",
    "def load_obj_vf():\n",
    "    object_ids = list(np.load('{0}/relationships/object_ids.npy'.format(vg_dir)))\n",
    "    filtered_obj_ids = set([\n",
    "        obj_id\n",
    "        for item in triplets\n",
    "        for obj_id in [item[1][1], item[3][1]]\n",
    "    ])\n",
    "    \n",
    "    chunck_size = 100000\n",
    "    visual_features = []\n",
    "    for l in range(0, len(object_ids), chunck_size):\n",
    "        vfs = np.load('{0}/relationships/objects_resnet50_features_[{1}].npy'.format(vg_dir, l), allow_pickle=True)\n",
    "        visual_features += [\n",
    "            (iid, vf)\n",
    "            for iid, vf in zip(object_ids[l:l+chunck_size], vfs)\n",
    "            if iid in filtered_obj_ids\n",
    "            if type(vf) != int\n",
    "        ]\n",
    "    return dict(visual_features)\n",
    "\n",
    "def filter_rels1():\n",
    "    # clean the data from examples in which there is no saved vector for them\n",
    "    return [\n",
    "        item\n",
    "        for item in triplets\n",
    "        if item[0] in img_visual_features \n",
    "        if type(img_visual_features[item[0]]) != int\n",
    "    ]\n",
    "\n",
    "def filter_rels2():\n",
    "    # clean the data from examples in which there is no saved vector for them\n",
    "    return [\n",
    "        item\n",
    "        for item in triplets\n",
    "        if item[0] in img_visual_features \n",
    "        if type(img_visual_features[item[0]]) != int\n",
    "        if item[1][1] in visual_features \n",
    "        if type(visual_features[item[1][1]]) != int\n",
    "        if item[3][1] in visual_features \n",
    "        if type(visual_features[item[3][1]]) != int\n",
    "    ]\n",
    "    \n",
    "\n",
    "# run them in this order with silly report about time consumption:\n",
    "images = silly_report(load_images, 'loading image names')\n",
    "rels_from_file = silly_report(load_rels, 'loading relationships corpus')\n",
    "image_ids = silly_report(load_image_ids, 'loading pre-processed image ids')\n",
    "triplets = silly_report(preprocess_rels, 'preprocess rels into triplets+bbox')\n",
    "img_visual_features = silly_report(load_img_vf, 'loading image visual features')\n",
    "triplets = silly_report(filter_rels1, 'filtering relations')\n",
    "visual_features = silly_report(load_obj_vf, 'loading bbox visual features')\n",
    "triplets = silly_report(filter_rels2, 'filtering relations')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#vocab = Counter([w.strip() for _,(sbj,_,_),pred,(obj,_,_) in triplets for w in ' '.join([sbj,pred,obj]).split(' ')])\n",
    "#np.save('visual_genome/data/relationships/vocab_caption.npy', vocab)\n",
    "vocab = np.load('{0}/relationships/vocab_caption.npy'.format(vg_dir), allow_pickle=True)[None][0]\n",
    "\n",
    "word2ix = {w:i for i,w in enumerate(['<0>', '<s>']+list(vocab))}\n",
    "ix2word = {i:w for w,i in word2ix.items()}\n",
    "word2onehot = lambda w: np.array([0.]*word2ix[w] + [1.] + [0.]*(len(word2ix)-word2ix[w]-1))\n",
    "\n",
    "#max_len = max(len(' '.join([sbj,pred,obj]).split(' ')) for _,(sbj,_,_),pred,(obj,_,_) in triplets)\n",
    "max_len = 16 # if not filtering triplets with test-images this should be the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item2features(item):\n",
    "    img_id,(sbj,object_id1,sbj_bbx),pred,(obj,object_id2,obj_bbx) = item\n",
    "\n",
    "    # visual features\n",
    "    vf0 = img_visual_features[img_id]\n",
    "    vf1 = visual_features[object_id1]\n",
    "    vf2 = visual_features[object_id2]\n",
    "\n",
    "    # spatial features\n",
    "    # based on VisKE\n",
    "    a1 = sbj_bbx[2] * sbj_bbx[3]\n",
    "    a2 = obj_bbx[2] * obj_bbx[3]\n",
    "    if obj_bbx[0] <= sbj_bbx[0] <= obj_bbx[0]+obj_bbx[2] <= sbj_bbx[0] + sbj_bbx[2]:\n",
    "        # overlap\n",
    "        w = (obj_bbx[0]+obj_bbx[2]) - (sbj_bbx[0])\n",
    "    elif obj_bbx[0] <= sbj_bbx[0] <= sbj_bbx[0] + sbj_bbx[2] <= obj_bbx[0]+obj_bbx[2]:\n",
    "        # obj contains sbj\n",
    "        w = sbj_bbx[2]\n",
    "    elif sbj_bbx[0] <= obj_bbx[0] <= sbj_bbx[0] + sbj_bbx[2] <= obj_bbx[0]+obj_bbx[2]:\n",
    "        # overlaps\n",
    "        w = (sbj_bbx[0]+sbj_bbx[2]) - (obj_bbx[0])\n",
    "    elif sbj_bbx[0] <= obj_bbx[0] <= obj_bbx[0]+obj_bbx[2] <= sbj_bbx[0] + sbj_bbx[2]:\n",
    "        # subj contains obj\n",
    "        w = obj_bbx[2]\n",
    "    else:\n",
    "        w = 0\n",
    "\n",
    "    if obj_bbx[1] <= sbj_bbx[1] <= obj_bbx[1]+obj_bbx[3] <= sbj_bbx[1] + sbj_bbx[3]:\n",
    "        # overlap\n",
    "        h = (obj_bbx[1]+obj_bbx[3]) - (sbj_bbx[1])\n",
    "    elif obj_bbx[1] <= sbj_bbx[1] <= sbj_bbx[1] + sbj_bbx[3] <= obj_bbx[1]+obj_bbx[3]:\n",
    "        # obj contains sbj\n",
    "        h = sbj_bbx[3]\n",
    "    elif sbj_bbx[1] <= obj_bbx[1] <= sbj_bbx[1] + sbj_bbx[3] <= obj_bbx[1]+obj_bbx[3]:\n",
    "        # overlaps\n",
    "        h = (sbj_bbx[1]+sbj_bbx[3]) - (obj_bbx[1])\n",
    "    elif sbj_bbx[1] <= obj_bbx[1] <= obj_bbx[1]+obj_bbx[3] <= sbj_bbx[1] + sbj_bbx[3]:\n",
    "        # subj contains obj\n",
    "        h = obj_bbx[3]\n",
    "    else:\n",
    "        h = 0\n",
    "\n",
    "    overlap_a = w * h\n",
    "\n",
    "    # dx; dy; ov; ov1; ov2; h1;w1; h2;w2; a1; a2\n",
    "    sf1 = [\n",
    "        #obj_bbx[0] - sbj_bbx[0], # dx = x2 - x1 \n",
    "        #obj_bbx[1] - sbj_bbx[1], # dy = y2 - y1\n",
    "        obj_bbx[0] - sbj_bbx[0] + (obj_bbx[2] - sbj_bbx[2])/2, # dx = x2 - x1 + (w2 - w1)/2\n",
    "        obj_bbx[1] - sbj_bbx[1] + (obj_bbx[3] - sbj_bbx[3])/2, # dy = y2 - y1 + (h2 - h1)/2\n",
    "        0 if (a1+a2) == 0 else overlap_a/(a1+a2), # ov\n",
    "        0 if a1 == 0 else overlap_a/a1, # ov1\n",
    "        0 if a2 == 0 else overlap_a/a2, # ov2\n",
    "        sbj_bbx[3], # h1\n",
    "        sbj_bbx[2], # w1\n",
    "        obj_bbx[3], # h2\n",
    "        obj_bbx[2], # w2\n",
    "        a1, # a1\n",
    "        a2, # a2\n",
    "    ]\n",
    "    \n",
    "    # spatial template (two attention masks)\n",
    "    x1, y1, w1, h1 = sbj_bbx\n",
    "    x2, y2, w2, h2 = obj_bbx\n",
    "\n",
    "    mask = np.zeros([7,7,2])\n",
    "    mask[int(y1*7):int((y1+h1)*7), int(x1*7):int((x1+w1)*7), 0] = 1 # mask bbox 1 \n",
    "    mask[int(y2*7):int((y2+h2)*7), int(x2*7):int((x2+w2)*7), 0] = 1 # mask bbox 2\n",
    "\n",
    "    sf2 = mask.flatten()\n",
    "    \n",
    "    # sentence encoding\n",
    "    sent = ' '.join([sbj,pred,obj]).split(' ')\n",
    "    sent = [word2ix['<s>']]+[word2ix[w] for w in sent]+[word2ix['<0>']]*(1+max_len-len(sent))\n",
    "\n",
    "    return vf0, sf1, sf2, vf1, vf2, sent\n",
    "\n",
    "def generator_features_description(\n",
    "        batch_size=32,\n",
    "        split=(0.,1.),\n",
    "        all_data = triplets,\n",
    "        mode='bbox',\n",
    "        spatial_order=None,\n",
    "        shuffle=True,\n",
    "    ):\n",
    "    while True:\n",
    "        gc.collect()\n",
    "        \n",
    "        _all_data = all_data[int(len(all_data)*split[0]):int(len(all_data)*split[1])]\n",
    "\n",
    "        # shuffle \n",
    "        if shuffle:\n",
    "            np.random.shuffle(_all_data)\n",
    "        \n",
    "        \n",
    "        # start\n",
    "        X_vfs = []\n",
    "        X_sfs = []\n",
    "        X_objs = []\n",
    "        X_sents = []\n",
    "        \n",
    "        for item in _all_data:\n",
    "            vf0, sf1, sf2, vf1, vf2, sent = item2features(item)\n",
    "            \n",
    "            X_vfs.append(vf0)\n",
    "            X_sents.append(sent)\n",
    "            \n",
    "            if mode[:4] == 'bbox' or mode[-4:] == 'bbox':\n",
    "                X_sfs.append(sf1)\n",
    "            elif mode[:9] == 'attention':\n",
    "                X_sfs.append(sf2)\n",
    "            \n",
    "            if mode[:4] == 'bbox' or mode[:9] == 'attention' or mode[:8] == 'implicit':\n",
    "                l = [vf1, vf2]\n",
    "                \n",
    "                if mode[-2:] == '-r' and spatial_order is None:\n",
    "                    np.random.shuffle(l)\n",
    "                else:\n",
    "                    l = [l[i] for i in spatial_order]\n",
    "                    \n",
    "                X_objs.append(l)\n",
    "\n",
    "            if len(X_sents) == batch_size:\n",
    "                sents = np.array(X_sents)\n",
    "                if mode[:4] == 'bbox' or mode[:9] == 'attention':\n",
    "                    yield ([np.array(X_vfs), np.array(X_sfs), np.array(X_objs), sents[:, :-1]], np.expand_dims(sents[:, 1:], 2))\n",
    "                    \n",
    "                elif mode[:8] == 'implicit':\n",
    "                    yield ([np.array(X_vfs), np.array(X_objs), sents[:, :-1]], np.expand_dims(sents[:, 1:], 2))\n",
    "                    \n",
    "                elif mode == 'spatial_adaptive-bbox':\n",
    "                    yield ([np.array(X_vfs), np.array(X_sfs), sents[:, :-1]], np.expand_dims(sents[:, 1:], 2))\n",
    "\n",
    "                elif mode[:7] == 'no-beta' or mode == 'spatial_adaptive' or mode == 'spatial_adaptive-attention':\n",
    "                    yield ([np.array(X_vfs), sents[:, :-1]], np.expand_dims(sents[:, 1:], 2))\n",
    "                    \n",
    "                X_vfs = []\n",
    "                X_sfs = []\n",
    "                X_objs = []\n",
    "                X_sents = []\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [\n",
    "    'no-beta',\n",
    "    'implicit',\n",
    "    'spatial_adaptive',\n",
    "    'bbox',\n",
    "    'attention',\n",
    "    'spatial_adaptive-bbox',\n",
    "    'spatial_adaptive-attention',\n",
    "    'bbox-r',\n",
    "    'attention-r',\n",
    "    'implicit-r',\n",
    "]\n",
    "\n",
    "mode2title = {}\n",
    "mode2title['no-beta'] = 'simple'\n",
    "mode2title['implicit'] = 'td'\n",
    "mode2title['attention'] = 'td + mask'\n",
    "mode2title['bbox'] = 'td + VisKE'\n",
    "mode2title['implicit-r'] = 'td (rand)'\n",
    "mode2title['attention-r'] = 'td + mask (rand)'\n",
    "mode2title['bbox-r'] = 'td + VisKE (rand)'\n",
    "mode2title['spatial_adaptive'] = 'bu49'\n",
    "mode2title['spatial_adaptive-bbox'] = 'bu49 + mask'\n",
    "mode2title['spatial_adaptive-attention'] = 'bu49 + VisKE'\n",
    "\n",
    "n_epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "loading all models in 96.59s  \n"
     ]
    }
   ],
   "source": [
    "# model file directory\n",
    "dir_path = '{0}/relationships/'.format(vg_dir)\n",
    "#dir_path = 'saved_models0'\n",
    "\n",
    "# model file names\n",
    "models = {\n",
    "    mode: 'caption_model_{0}_{1}epochs.h5'.format(mode, n_epochs)\n",
    "    for mode in modes\n",
    "    if Path(dir_path + 'caption_model_{0}_{1}epochs.h5'.format(mode, n_epochs)).is_file() \n",
    "}\n",
    "\n",
    "# how to load models from file names\n",
    "def load_all_models():\n",
    "    return {\n",
    "        mode: load_model(dir_path + filename)\n",
    "        for mode, filename in models.items()\n",
    "    }\n",
    "# this is how to load models\n",
    "models = silly_report(load_all_models, 'loading all models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no-beta': <keras.engine.training.Model at 0x7f67c9fa7a58>,\n",
       " 'implicit': <keras.engine.training.Model at 0x7f67ca0e3ac8>,\n",
       " 'spatial_adaptive': <keras.engine.training.Model at 0x7f67ca7c3668>,\n",
       " 'bbox': <keras.engine.training.Model at 0x7f67cae154a8>,\n",
       " 'attention': <keras.engine.training.Model at 0x7f67cb596940>,\n",
       " 'spatial_adaptive-bbox': <keras.engine.training.Model at 0x7f67cbdd0588>,\n",
       " 'spatial_adaptive-attention': <keras.engine.training.Model at 0x7f67cc5006d8>,\n",
       " 'bbox-r': <keras.engine.training.Model at 0x7f67ccc4e470>,\n",
       " 'attention-r': <keras.engine.training.Model at 0x7f67cd3d0278>,\n",
       " 'implicit-r': <keras.engine.training.Model at 0x7f63907c0128>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the spatial relations dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of spatial relations from two books.\n",
    "composit_simple = np.load('composit2simple.npy')\n",
    "composit_simple = composit_simple.T\n",
    "simple_classes_set = list(set(composit_simple[:,1]))\n",
    "simple_classes = {\n",
    "    composit: simple_classes_set.index(simple)\n",
    "    for composit,simple in composit_simple\n",
    "}\n",
    "\n",
    "simple2composit = {\n",
    "    rel: [composit for composit,simple in composit_simple if rel == simple]\n",
    "    for rel in simple_classes_set\n",
    "}\n",
    "\n",
    "composit2simple = {\n",
    "    composit: simple\n",
    "    for composit,simple in composit_simple\n",
    "}\n",
    "\n",
    "# the simple form of spatial relations in this evaluation dataset\n",
    "rels = Counter(composit2simple[rel] for _,_,rel,_ in triplets if rel in composit2simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create buckets of examples with fixed size of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make buckets of evaluation for each spatial relation\n",
    "bucket_size = 40\n",
    "buckets = dict()\n",
    "for rel in rels:\n",
    "    _triplets = [item for item in triplets if item[2] in composit2simple and composit2simple[item[2]] == rel]\n",
    "    if len(_triplets) > 40:\n",
    "        np.random.shuffle(_triplets)\n",
    "        buckets[rel] = _triplets[:bucket_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Loss \n",
    "Run this part if you want to reproduce the results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the overall results are stored under 'None' index \n",
    "results[None] = dict()\n",
    "for mode, model in models.items():\n",
    "    results[None][mode] = dict()\n",
    "    for so in [(0,1)]:\n",
    "        out = model.evaluate_generator(\n",
    "            generator_features_description(\n",
    "                batch_size=batch_size,\n",
    "                split=(0,1.),\n",
    "                mode=mode, \n",
    "                spatial_order=so,\n",
    "                shuffle=False,\n",
    "                ),\n",
    "            steps=int(len(triplets)/batch_size)\n",
    "        )\n",
    "        results[None][mode] = out\n",
    "        print('{0:18} : {1:0.4f}'.format(mode2title[mode], out))\n",
    "        \n",
    "\n",
    "for mode in results[None]:\n",
    "    results[None][mode] = {(0,1): results[None][mode]}\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# report the results for each bucket\n",
    "for rel, _triplets in buckets.items():\n",
    "    print('====== {} ======'.format(rel))\n",
    "    results[rel] = dict()\n",
    "    for mode, model in models.items():\n",
    "        results[rel][mode] = dict()\n",
    "        if mode in ['bbox', 'implicit', 'attention', 'bbox-r', 'implicit-r', 'attention-r']:\n",
    "            spatial_orders = [(0,1), (1,0)]\n",
    "        else: \n",
    "            spatial_orders = [None]\n",
    "        \n",
    "        for spatial_order in spatial_orders:\n",
    "            out = model.evaluate_generator(\n",
    "                generator_features_description(\n",
    "                    batch_size=bucket_size,\n",
    "                    split=(0,1.),\n",
    "                    mode=mode,\n",
    "                    all_data=_triplets,\n",
    "                    spatial_order=spatial_order,\n",
    "                ),\n",
    "                steps=int(len(_triplets)/bucket_size),\n",
    "            )\n",
    "            results[rel][mode][spatial_order] = out\n",
    "            print('{0:18} ({2}): {1:0.4f}'.format(\n",
    "                mode if mode not in mode2title else mode2title[mode],\n",
    "                out,\n",
    "                'lnd-trg' if spatial_order == (1,0) else 'trg-lnd'\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the results?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save('ablation/results.npy', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The attention models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_archs = {\n",
    "    'bbox',\n",
    "    'attention',\n",
    "    'implicit',\n",
    "    'bbox-r',\n",
    "    'attention-r',\n",
    "    'implicit-r',\n",
    "}\n",
    "\n",
    "att_models = dict()\n",
    "for mode, model in models.items():\n",
    "    if mode not in att_archs:\n",
    "        continue\n",
    "    inputs = model.inputs\n",
    "    att_models[mode] = Model(inputs, model.layers[-2].input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates the test data for predict method\n",
    "def generator_wraper(generator):\n",
    "    for o1, o2 in generator:\n",
    "        yield o1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1-normalisation (considering that all values are positive)\n",
    "def normalize(x):\n",
    "    return x / np.expand_dims(x.sum(-1), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention probes\n",
    "Run this only for re-prodicing the attentions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "att_results = dict()\n",
    "\n",
    "for rel, _triplets in buckets.items():\n",
    "    print('====== {} ======'.format(rel))\n",
    "    \n",
    "    att_results[rel] = dict()\n",
    "    for mode, model in att_models.items():\n",
    "        att_results[rel][mode] = dict()\n",
    "        if mode in ['bbox', 'implicit', 'attention', 'bbox-r', 'implicit-r', 'attention-r']:\n",
    "            spatial_orders = [(0,1), (1,0)]\n",
    "        else: \n",
    "            spatial_orders = [None]\n",
    "        \n",
    "        for so in spatial_orders:\n",
    "            out = model.predict_generator(\n",
    "                generator_wraper(generator_features_description(\n",
    "                    batch_size=bucket_size, \n",
    "                    split=(0,1.), \n",
    "                    mode=mode, \n",
    "                    all_data=_triplets,\n",
    "                    spatial_order=so,\n",
    "                    shuffle=False,\n",
    "                )),\n",
    "                steps=int(len(_triplets)/bucket_size),\n",
    "            )\n",
    "            \n",
    "            sents = np.array([item2features(item)[-1][1:] for item in _triplets])\n",
    "            sents_mask = np.expand_dims(np.array(sents != 0, dtype=np.float), 2)\n",
    "\n",
    "            if len(out) == 4:\n",
    "                lm, sp, vs, alpha = out\n",
    "                lm_norms = np.expand_dims(np.linalg.norm(lm, axis=-1), 2)\n",
    "                vs_norm = np.repeat(np.expand_dims(np.linalg.norm(vs, axis=-1), 1), lm.shape[1], axis=1)\n",
    "                sp_norm = np.repeat(np.expand_dims(np.expand_dims(np.linalg.norm(sp, axis=-1), 1), 1), lm.shape[1], axis=1)\n",
    "                norms = np.concatenate([lm_norms, sp_norm, vs_norm, ], axis=2)\n",
    "                att_results[rel][mode][so] = [norms, alpha, sents]\n",
    "            else:\n",
    "                lm, vs, alpha = out\n",
    "                lm_norms = np.expand_dims(np.linalg.norm(lm, axis=-1), 2)\n",
    "                vs_norm = np.repeat(np.expand_dims(np.linalg.norm(vs, axis=-1), 1), lm.shape[1], axis=1)\n",
    "                norms = np.concatenate([lm_norms, vs_norm], axis=2)\n",
    "                att_results[rel][mode][so] = [norms, alpha, sents]\n",
    "                \n",
    "            print('{0:18} ({2}): {1}'.format(\n",
    "                mode if mode not in mode2title else mode2title[mode],\n",
    "                ' '.join(['{0:0.4f}'.format(f) for f in normalize(att_results[rel][mode][so][0]).mean(0).mean(0)]),\n",
    "                'lnd-trg' if so == (1,0) else 'trg-lnd'\n",
    "            ))\n",
    "\n",
    "_triplets = triplets\n",
    "rel = None\n",
    "att_results[rel] = dict()\n",
    "for mode, model in att_models.items():\n",
    "    att_results[rel][mode] = dict()\n",
    "    if mode in ['bbox', 'implicit', 'attention', 'bbox-r', 'implicit-r', 'attention-r']:\n",
    "        spatial_orders = [(0,1), (1,0)]\n",
    "    else: \n",
    "        spatial_orders = [None]\n",
    "\n",
    "    for so in spatial_orders:\n",
    "        out = model.predict_generator(\n",
    "            generator_wraper(generator_features_description(\n",
    "                batch_size=bucket_size, \n",
    "                split=(0,1.), \n",
    "                mode=mode, \n",
    "                all_data=_triplets,\n",
    "                spatial_order=so,\n",
    "                shuffle=False,\n",
    "            )),\n",
    "            steps=int(len(_triplets)/bucket_size),\n",
    "        )\n",
    "\n",
    "        sents = np.array([item2features(item)[-1][1:] for item in _triplets])\n",
    "        sents_mask = np.expand_dims(np.array(sents != 0, dtype=np.float), 2)\n",
    "\n",
    "        if len(out) == 4:\n",
    "            lm, sp, vs, alpha = out\n",
    "            lm_norms = np.expand_dims(np.linalg.norm(lm, axis=-1), 2)\n",
    "            vs_norm = np.repeat(np.expand_dims(np.linalg.norm(vs, axis=-1), 1), lm.shape[1], axis=1)\n",
    "            sp_norm = np.repeat(np.expand_dims(np.expand_dims(np.linalg.norm(sp, axis=-1), 1), 1), lm.shape[1], axis=1)\n",
    "            norms = np.concatenate([lm_norms, sp_norm, vs_norm, ], axis=2)\n",
    "            att_results[rel][mode][so] = [norms, alpha, sents]\n",
    "        else:\n",
    "            lm, vs, alpha = out\n",
    "            lm_norms = np.expand_dims(np.linalg.norm(lm, axis=-1), 2)\n",
    "            vs_norm = np.repeat(np.expand_dims(np.linalg.norm(vs, axis=-1), 1), lm.shape[1], axis=1)\n",
    "            norms = np.concatenate([lm_norms, vs_norm], axis=2)\n",
    "            att_results[rel][mode][so] = [norms, alpha, sents]\n",
    "            \n",
    "        print('{0:18} ({2}): {1}'.format(\n",
    "            mode if mode not in mode2title else mode2title[mode],\n",
    "            ' '.join(['{0:0.4f}'.format(f) for f in normalize(att_results[rel][mode][so][0]).mean(0).mean(0)]),\n",
    "            'lnd-trg' if so == (1,0) else 'trg-lnd'\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_att_results = {}\n",
    "# for each attention results (based samples in each bucket of relation)\n",
    "for rel in att_results:\n",
    "    if rel is None:\n",
    "        _triplets = triplets[:-(len(triplets)%batch_size)]\n",
    "    else:\n",
    "        _triplets = buckets[rel]\n",
    "    \n",
    "    triplet_att_results[rel] = dict()\n",
    "    for mode in att_results[rel]:\n",
    "        triplet_att_results[rel][mode] = dict()\n",
    "        for so in att_results[rel][mode]:\n",
    "            triplet_att_results[rel][mode][so] = []\n",
    "            \n",
    "            # the attentions\n",
    "            norms, alpha, sents = att_results[rel][mode][so]\n",
    "            \n",
    "            # find the image, and the bounding boxes associated with each sample\n",
    "            for i, (img_id, (_trg,_,bbox1), _rel, (_lnd,_,bbox2)) in enumerate(_triplets):\n",
    "                # figuer out the path\n",
    "                #filename = images[img_id]['path']\n",
    "                \n",
    "                # normalisation!\n",
    "                a = norms[i] * alpha[i]\n",
    "                a = a / np.expand_dims(a.sum(-1), -1)\n",
    "\n",
    "                pos_start = 0\n",
    "                a_trg = [\n",
    "                    np.mean(a[pos_start:pos_start+len(_trg.split(' ')), j], 0)\n",
    "                    for j in range(a.shape[1])\n",
    "                ]\n",
    "                \n",
    "                pos_start += len(_trg.split(' '))\n",
    "                a_rel = [\n",
    "                    np.mean(a[pos_start:pos_start+len(_rel.split(' ')), j], 0)\n",
    "                    for j in range(a.shape[1])\n",
    "                ]\n",
    "                \n",
    "                pos_start += len(_rel.split(' '))\n",
    "                a_lnd = [\n",
    "                    np.mean(a[pos_start:pos_start+len(_lnd.split(' ')), j], 0)\n",
    "                    for j in range(a.shape[1])\n",
    "                ]\n",
    "                \n",
    "                triplet_att_results[rel][mode][so].append([a_trg, a_rel, a_lnd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save attentions and the inputs to these attentions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.save('attentions/att_results.npy', att_results)\n",
    "np.save('attentions/triplet_att_results.npy', triplet_att_results)\n",
    "np.save('attentions/triplets.npy', triplets)\n",
    "np.save('attentions/buckets.npy', buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trees', 'on side of', 'slope', 'side')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg, rel, lnd, _rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig.clf()\n",
    "ax.cla()\n",
    "plt.close('all')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 17, 4)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(att_results[_rel]['bbox'][(0,1)][0] * att_results[_rel]['bbox'][(0,1)][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (3 entries)\n"
     ]
    }
   ],
   "source": [
    "%reset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAE+CAYAAAB2l1BaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt8VNW5//HPE8ALoOIRVC5qwHINkHD3glZbFVSEqlBFBUG84E9qlYNH68GKp9VitXqsP5Vi9YhXsGgVPSjWFlREKgRJuFgsAgqCFqWAoEEgz/ljz6RDTMiAM3tg8X2/XnnBntnZz5pJ8p211957bXN3REQkLHm5boCIiGSewl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKd9mrmdkKMzst5po3m9nv46wpsqsU7rLHylFw/87MHq/i8Y5mtsXM/s3d73D3y9PY1gwzuzxl+RQz+6eZXZhYdjPbbGabUr7+I7OvSPZVCnfZJySCdUYaqz4GnGdm9So9Phh42d3X7Wb9M4AXgMvcfWLKU4XuXj/l69e7s32RyhTuskcysyeAo4GXUnu0ZjbIzD4ysy/M7D8zXdfd3wE+Ac5PaUst4CJgQmJ5jJk9mfj/AWb2ZKI9681sjpkdUem19AGeBS5y9z9mus0iVVG4yx7J3QcBHwPnJHu0ZtYOeAgYBDQBDgOaZaH840Q99aTTgDrAK1WseylwCHBUoj3Dga9Tnj8HeBLo7+5Ts9BWkSop3GVv0p9oaORNd98C3AKUZ6HOE8D3zSz5wTEYeNrdt1ax7laiUP+eu29392J335jy/KnAB8Db1dSal+jxJ796ZepFyL5N4S57kybAyuSCu28GvqhuZTO7KRmawMtAz9Qgre773P1j4E3gEjOrD/yIxJBMFZ4ApgETzWy1mf3azOqkPH8LsAV4wcz2r+L7O7t7g5SvadW1S2RXKNxlT1Z5ytI1RMMfAJhZXaJec9Xf7D42GZpAH2BmapDWUHsCUY/9fGC5u8+rpsZWd7/N3dsBJyTqpA7pbAbOIhq6mVwp+EWyRuEue7LPgBYpy5OBPmbW08z2A/6L7P0OP0f0QXIb1ffaMbNTzaxD4qDrRqJhmu2p67j7l0Bvoj2PpxPrimSVwl32ZL8CRieGUUa5+yLgGuBpol78P4FV2SicGPJJBvxTO1n1SKIPnY3A+8AbRAdQK29vPXA60Ap43MySf3sllc5z/+8MvgzZh5lu1iEiEh713EVEAqRwFxEJkMJdRCRACncRkQDVzlXhhg0ben5+fq7Ki4jslYqLiz9390Y1rZezcM/Pz2fu3Lm5Ki8islcys4/SWU/DMiIiAVK4i4gESOEuIhIghbuISIAU7iIiAVK4i4gEqMZwN7NHzewfZrawmufNzH5rZkvNrNTMOme+mSIisivS6bk/RjQXdXXOBFomvq4kuseliIjkUI3h7u5vAut2sko/4HGPzAYamFnjTDVQRER2XSauUG1Kyn0tiW6e0JToZgo7MLMriXr3HH300btd8JqLq7zjWUY98FTVo0u5rB1HfdWOv/bO6qv2vlU7kzJxQNWqeKzKO4C4+3h37+ruXRs1qnFqBBER2U2ZCPdVpNy0GGgGrM7AdkVEZDdlItynAIMTZ80cB2xw928NyYiISHxqHHM3s2eAU4CGZrYKuBWoA+Du44CpwFnAUuArYGi2GisiIumpMdzdfWANzzvRHelFRGQPoStURUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEC1c90AEdkz9Z49IIYqH8ZQY9+UVs/dzHqb2RIzW2pmN1Xx/CFm9pKZlZjZIjMbmvmmiohIumoMdzOrBTwAnAm0AwaaWbtKq10DLHb3QuAU4Ddmtl+G2yoiImlKZ1imO7DU3ZcBmNlEoB+wOGUdBw4yMwPqA+uAbRluq+RY9nfTtYsukinpDMs0BVamLK9KPJbq/wNtgdXAAuCn7l5eeUNmdqWZzTWzuWvXrt3NJouISE3S6blbFY95peVewHzgB8CxwJ/M7C1337jDN7mPB8YDdO3atfI2RKqlvQaRXZNOuK8CjkpZbkbUQ081FBjr7g4sNbPlQBvg3Yy0UiSHdNZI/HL5nofy805nWGYO0NLMmicOkl4ITKm0zsfADwHM7AigNbAskw0VEZH01dhzd/dtZjYCmAbUAh5190VmNjzx/DjgF8BjZraAaBjnRnf/PIvtFtknhNKLlPildRGTu08FplZ6bFzK/1cDZ2S2aSIisrs0/YCISIAU7iIiAVK4i4gESOEuIhIghbuISIAU7iIiAVK4i4gESOEuIhIghbuISIAU7iIiAVK4i4gESOEuIhIghbuISIAU7iIiAVK4i4gESOEuIhIghbuISIAU7iIiAVK4i4gESOEuIhIghbuISIBq57oBe5veswfEUOXDGGqISMjUcxcRCZB67rJX6Dt4WVa371nduuxNsv27BvH8vinc9zLZHxbSkJBEQgm5fZWGZUREAqSeu6RtXx0aUQ9W9kbquYuIBEjhLiISIA3LiOzB9tUhoX31dWeSeu4iIgFSuIuIBCitcDez3ma2xMyWmtlN1axzipnNN7NFZvZGZpspIiK7osYxdzOrBTwAnA6sAuaY2RR3X5yyTgPgQaC3u39sZodnq8EiIlKzdHru3YGl7r7M3b8BJgL9Kq1zEfC8u38M4O7/yGwzRURkV6QT7k2BlSnLqxKPpWoFHGpmM8ys2MwGV7UhM7vSzOaa2dy1a9fuXotFRKRG6YS7VfFY5bOIagNdgLOBXsAtZtbqW9/kPt7du7p710aNGu1yY0VEJD3pnOe+CjgqZbkZsLqKdT53983AZjN7EygEPshIK0VEZJek03OfA7Q0s+Zmth9wITCl0jovAieZWW0zqwv0AN7PbFNFRCRdNfbc3X2bmY0ApgG1gEfdfZGZDU88P87d3zezV4FSoBz4vbsvzGbDRUSkemlNP+DuU4GplR4bV2n5LuCuzDWterrVnYjIzmlumb3MvjrtrojsGk0/ICISIIW7iEiAFO4iIgHSmLukbQxjct0EEUmTwn0X6SYCuaEPFpFdo2EZEZEAKdxFRAKkcBcRCZDCXUQkQAp3EZEA6WwZkRrsq2fq7KuvOxTquYuIBEjhLiISIIW7iEiANOYusgfTuHf8QnnP1XMXEQnQXtlz35fndwmlVyEi2aWeu4hIgPbKnnsuqecsInsDhbuI7HHUifruNCwjIhIghbuISID2ymEZ7bKJiOyceu4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFKK9zNrLeZLTGzpWZ2007W62Zm282sf+aaKCIiu6rGcDezWsADwJlAO2CgmbWrZr07gWmZbqSIiOyadHru3YGl7r7M3b8BJgL9qljvJ8BzwD8y2D4REdkN6YR7U2BlyvKqxGMVzKwpcC4wbmcbMrMrzWyumc1du3btrrZVRETSlE64WxWPVb7F6H8DN7r79p1tyN3Hu3tXd+/aqFGjdNsoIiK7KJ0pf1cBR6UsNwNWV1qnKzDRzAAaAmeZ2TZ3fyEjrRQRkV2STrjPAVqaWXPgE+BC4KLUFdy9efL/ZvYY8LKCXUQkd2oMd3ffZmYjiM6CqQU86u6LzGx44vmdjrOLiEj80roTk7tPBaZWeqzKUHf3Id+9WSIi8l3oClURkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRACncRkQAp3EVEAqRwFxEJkMJdRCRAaYW7mfU2syVmttTMbqri+YvNrDTxNcvMCjPfVBERSVeN4W5mtYAHgDOBdsBAM2tXabXlwPfdvSPwC2B8phsqIiLpS6fn3h1Y6u7L3P0bYCLQL3UFd5/l7v9MLM4GmmW2mSIisivSCfemwMqU5VWJx6ozDHilqifM7Eozm2tmc9euXZt+K0VEZJekE+5WxWNe5YpmpxKF+41VPe/u4929q7t3bdSoUfqtFBGRXVI7jXVWAUelLDcDVldeycw6Ar8HznT3LzLTPBER2R3p9NznAC3NrLmZ7QdcCExJXcHMjgaeBwa5+weZb6aIiOyKGnvu7r7NzEYA04BawKPuvsjMhieeHwf8HDgMeNDMALa5e9fsNVtERHYmnWEZ3H0qMLXSY+NS/n85cHlmmyYiIrtLV6iKiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiAQorXA3s95mtsTMlprZTVU8b2b228TzpWbWOfNNFRGRdNUY7mZWC3gAOBNoBww0s3aVVjsTaJn4uhJ4KMPtFBGRXZBOz707sNTdl7n7N8BEoF+ldfoBj3tkNtDAzBpnuK0iIpImc/edr2DWH+jt7pcnlgcBPdx9RMo6LwNj3X1mYvnPwI3uPrfStq4k6tkDtAaWZOqFpKEh8HmM9VRbtVVbtbPhGHdvVNNKtdPYkFXxWOVPhHTWwd3HA+PTqJlxZjbX3buqtmqrtmqHUntn0hmWWQUclbLcDFi9G+uIiEhM0gn3OUBLM2tuZvsBFwJTKq0zBRicOGvmOGCDu6/JcFtFRCRNNQ7LuPs2MxsBTANqAY+6+yIzG554fhwwFTgLWAp8BQzNXpN3W06Gg1RbtVVbtXOhxgOqIiKy99EVqiIiAVK4i4gESOEuIhKg4MPdzOrlqO6J6TyWpdoD0nlMMsPM8szsxzmqXcvMnsxRbTOzo2peU3Ih2AOqZnYC8HugvrsfbWaFwFXu/v9iqj/P3TvX9FiAtY8A7gCauPuZiXmIjnf3R2Ko/SEwG3gLeNPdF2e7ZkrtN9395LjqVao9DTgnMT1I3LWL3b1L3HUTtfcHzgfySTnzz93/K6b6J1RR+/E4aqcjnStU91b3Ar1InJPv7iVmlvU/PjM7HjgBaGRmI1OeOpjoVNJs1j6T6JTUpmb220q1t2WzdorHgP8B/jOx/AEwCch6uBNNbNcDOAm428zaACXufm4Mtf9kZqOIXuvm5IPuvi6G2iuAt81sSqXa98RQe7aZdXP3OTHUquxFYANQDGyJs7CZPQEcC8wHticedkDhHgd3X2m2w8wI26tbN4P2A+oTvbcHpTy+Eeif5dqrgblAX6Jf+KQvgeuzXDupobs/a2Y/g4rrJOJ43yH6+W5N/FsOfAb8I6balyX+vSblMQdaxFB7deIrjx1/5+JwKjDczFYQfbAY4O7eMYbazdy9dwx1qtIVaOd78NBHyOG+MrHb5Ikra68F3o+h7uXuPsjMNrj7f8dQr4K7lwAlZva0u2+Ns3aKzWZ2GIm5hZJXLMdUeyOwALgHeNjdv4ipLu7ePK5aVdS+LVe1iab7zpVZZtbB3RfkoPZC4Ehgj70SP+Qx94bAfcBpRL2J14CfZvsP3swWE/3CTwFOodKkanHspicO3I4BjiH6AE/2prLeizSzLsBvgfZEfwCNgP7uXhpD7X5AT6Jpqr8BZhGNvf85htp1gZHA0e5+pZm1BFq7+8sx1G4E/AdQAByQfNzdf5Dt2on6PYGW7v4/ibbUd/flMdRdTHQPiWVEwzKx7TWY2XSgCHiXlCEhd++b7drpCjbcc8XMrgWuJtodrzx5WlwB+zeiYZhiUoai4urJmlltoimdDVgS915EYqz9TOA64HB3PzCGmpOI3u/B7t7ezA4E3nH3ohhqv0Y01j8KGA5cCqx19xtjqH0r0RBFa3dvZWZNgD+4e9bPDDOzY4BDiY6xALwJrHf3j2Ko/f2qHnf3N7JdO13BhbuZ3U8V0w0nufu1MbXjIXe/Oo5aVdT+q7v3yFHtEqKgmeTuH8Zc+zmi3tRSYCbRH/tf3b0shtpz3b2rmb3n7p0Sj5W4e2EMtYvdvYuZlSZ7rWb2hrtXGUAZrj0f6ATMS3ndpTH1nn8KXA48T9SR+BHRcNz92a69NwhxzD15g5ATic6emJRYHsCOBxmzyt2vrrS72hA4KJu7qyn3rp1uZncR/dKn7jLOy1btFH2BC4Bnzayc6P1/1t0/jqH2WKKQiesAbqpvEr315LGGY4nvDI7kntEaMzubaI+xWUy1v3F3N7Pk647zupJhwHHuvjlR+07gHSBr4W5mM929p5l9yY6dyOSQ0MHZqr2rguu5JyXGxM5IDgmYWR3gNXc/Nab6se+uJl5zdTyuMdikxLjzLcDF7p7V00AT9eoQDYklT3l9AxgXx7CQmZ0OjCbqULxG1LkY4u4zYqjdh+jc/qOIgu1g4DZ3rzw1dzZqjyIa9z4d+BXRWUNPx9F7NrMFQLfknpmZHQDMcfcO2a69Nwg53JcQXTyzLrF8KDDb3VvHVD9nu6u5Zmb5wI+JevDbiYZofhND3d8DdYAJiYcGAds9cYvIGOofBhxH1Iub7e65uu1brBIfbGcQve5p7v6nmOqOJDq+8MfEQz8CHov7LLU9VYjDMkljgfdSerPfJzqDJC45212tdPFU0gag2N3nZ7n2X4kC9g/AAHdfls16lXSrNMb9l8QxgKxJGQpLSp4ad7SZHR3HUJiZtQIeAo5IHMztCPR191/GUPt6oj3SWAI9lbvfY2YziM6QMmCou78Xdzv2VMH23AHM7EiiKxYhOrD2aYy1c7m7+jTRkNBLiYfOJrqjVhuiP8RfZ7F2G3f/W7a2X0PteUQfKB8mllsAk7M57UJK5+EAove8hChoOhL9zvXMVu2UNrwB3AD8LmUvcaG7t4+h9q1Ee2nrgIlE7/dn2a4rNQsu3JPhUkWPCojtoGKyLbnaXZ0GnO/umxLL9YHJwLlEvfd2Wax9CHArO457/5e7Z/1CJjP7IdHUB8uI3vNjiHpzOzsWkanaE4HbkxfUmFl7YJS7D4mh9hx371bpTJ35cZyGmdKGjkTDcOcDq9z9tLhqS9VCHJYZCVwJpI7xpn6CxXZQMRHmse+uAkcTXcSTtBU4xt2/NrNsn8HxKNHFS8lZEgcRBe55Wa6Lu/85efEQUbj/zd3jOmOlTeqVku6+0MziCtfPE2fnJIcA+xP/lZP/AD4FvgAOj7m2VCG4cHf3KxP/fQh41d03mtktQGfgF9muX8UpUhVPEd+pUk8TTej0YmL5HOCZxLh/tmdKPNbdz09Zvi1xcDlrzKy6D45jzQx3fz6b9RPeTxzQfZLo538J8Ux3AdF8NuOBNmb2CbAcuDiOwmZ2NVGPvRHR3uEVHuNsnFK94IZlkpJnpiTONb+DqCd/c64u7olbYhqA5IGmme4+t4ZvyVTdd4Ab3H1mYvlE4G53Pz6LNf9nJ0+7u1+2k+cz1YYD2PE0zDeBh2K6gGp/oknp8oF/I5pjxz2GqW/NbCzwDNHrduAtj+Y4khwLOdzfc/dOZvYrYIG7P506JhkiMzs4safyb1U97/HMa1NEdCriIUQfLOuASz2GuWX2VWb2KrAemMeO003Ecfpp5atEzwXG6yrR3As53F8GPiGaOKwL8DXwbhyXg+dK4jWfQ/QHviL1KWKa1yalLQcTFd0YY81c3iik8mRtAMTxnsd1Zkw1tUuJ3uPkVaL1iObUCf56jj1dyLfZ+zEwDejt7uuJdldvyG2Tssvd+3j0aT3f3VukfDWPK9jN7DCLbhQyg2gahPsSF/fE4TGin3mTxPIHRJOHxeERoqmGewLdUr7iMMvMcnVVprHjfRK2Jx6THAvugGqSu39FtKuYXF7DHjz3cobNstzdHWci0Xhz8qDqxUTzy8RxalwubxSywd1fialWZT2BIWa2nJinviU6E+qvZpZ6lWgcd92SGgQ7LLMvs2ie61bAR8R8dxyr4p6alpgxMYbaM4g+VP7k7p0tulHInR7P7IhjiW6jGPtkbRZNffstHsPUt4n6nfnXwfs3dZXonkHhHqBc/rGb2d1EM3M+m3ioP1Dg7rfGULsz0cRZBcAi4r1RSPJCqeQfVPIDNdbJ2kSSFO6SESnn9xtQj3+Nw9YCNsVxfn/idMQRRDdG/5LE9K8xnY5Y1YdXLKcjilQl2DF3iZe7V9yYOXEqZktSbvkWk8eJzvG+I7E8EHiCaC7/bNuU8v8DgD7EdxGTyLeo5y4ZZWaXAz8lulnEfKIpcGe5+w9jqP2tOx9V9VgcEhcWTXH3XnHXFoGwT4WU3Pgp0SmAH3l0Y5ROQFzzmr+XOIgKgJn1AN6OqXZldYnuoyuSExqWkUwrc/cyM8PM9k/M0JnVG6Qk7sjjRPPIDzazjxPLx5D9uXQqtwGi4wyNAI23S84o3CXTVplZA+AF4E9m9k+ie3pmU58sbz8dqW3YBnzm7tty1RgRjblL1pjZ94nmmHnV3b+paX0RyRyFu4hIgHRAVUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQFmdW6a4uLhZXl7ea+Xl5W3QTXNFRL4rz8vL+1t5efkZXbp0WbWzFbMa7nl5ea8deeSRLY844gjLy9NOgojId1FeXm5r1qxpvXLlyll9+/Y9dsqUKVurWzeriVteXt7miCOOqK1gFxH57vLy8mjcuHFe7dq1jwIu3+m6WW6LeuwiIhmUl5eHmQF069u374HVrhdfk0REJIOSN6ipksJdRCRACncRkQDFepu9ay6el9HtPfBU57TWW7VqFW+//TYXXHBBRuvnos5Lxx6b0e2d8+GHaa33+uuvM2HCBJ544onvXHPYsGGcd955nH322d95W6ky2cadsdsye1av3xrPDXNmzJjBfvvtxwknnADAuHHjqFu3LoMHD672e8aMGUP9+vUZNWpUxttz2223ZXR7t956a43r1K9fn02bNmW07p5qn+i5//nPf2bevF37YNm+fXssdfYWJSUlFBYWZmRb8+fPz9i2krZv305JSQmdOnXK6HZDMmPGDGbNmlWxPHz48J0Gu+zdgg/3mTNnMnLkSCZPnkxRURF33XUXxx13HIWFhfTs2ZO1a9dWrDtgwABGjhzJqaeeyq9+9Svef/99Tj75ZDp27Mhdd93F9773PQCWL19Ov3796Nq1K927d2fJkiXfqrN8+fJcveSsKCkpoaioiMmTJ1f5/p177rmMHj2ak046iSOPPJLXX3+94ns/+OADevbsSYcOHbj33nv59NNPadasGQMGDGDEiBH07NmTY445hpkzZzJ48GBatWrFsGHDKr6/upqVf17JcN+yZQtDhgzh5ptvJpTbSG7evJmzzz6bwsJC2rdvz6RJk8jPz+fGG2+ke/fudO/enaVLlwLw0ksv0aNHDzp16sRpp53GZ599xooVKxg3bhz33nsvRUVFvPXWW4wZM4a7774bgIcffphu3bpRWFjI+eefz1dffZXLl5t1mzZt4oc//CGdO3emQ4cOvPjiiwCsWLGCtm3bcsUVV1BQUMAZZ5zB119/DcCcOXPo2LEjxx9/PDfccAPt27cH4LHHHmPEiBEV2+7Tpw8zZswA4Oqrr6Zr164UFBTssGcxdepU2rRpQ8+ePbn22mvp0ye6v/rmzZu57LLL6NatG506dapo1+4IPtx79uxJt27dePHFF5k/fz6XXXYZs2fPpqSkhNNPP51nn322Yt0FCxZQv359pk+fzk033cTFF1/MfffdR2lpKcuWLaN9+/Zs3bqVyy+/nHvuuYe5c+cyZswYxo4d+606zZs3z+Grzrxkz/3UU0+t8v1buHAhDRo04K233uLBBx/kqaeeAmDbtm1ccskl3HPPPSxYsIC///3vtGnTBoje7xYtWjBz5kwuvfRShg0bxp133snChQt5/vnn2bJlC0C1NVN/XqNHj6akpITDDz+cXr16cdppp3HHHXckTxnb67366qs0adKEkpISFi5cSO/evQE4+OCDeffddxkxYgTXXXcdEP3Oz549m/fee48LL7yQX//61+Tn5zN8+HCuv/565s+fz0knnbTD9s877zzmzJlDSUkJbdu25ZFHHon9NcbpgAMO4I9//CPz5s1j+vTp/Pu//3tFR+Dvf/8711xzDYsWLaJBgwY899xzAAwdOpRx48bxzjvvUKtWrbTq3H777cydO5fS0lLeeOMNSktLKSsr46qrruKVV15h5syZO3Qwb7/9dn7wgx8wZ84cpk+fzg033MDmzZt36zXGOuaeK0uWLKF169ZA9Ck7adIktmzZwqeffsodd9wBQFlZGevWrePnP/85AM8//zyFhYUVu/nt2rXj8MMP54UXXmDRokWcf/75QBReyT+U1Doh2bp1Kxs3bqRRo0b85je/+db799VXX7Fhwwauv/56IHpPGjRoAETvY9u2benevTsABQUFHHjggZSVlbF+/fqKQDrwwAMZNmwYjRs3BqBu3brst99+QNU/s8o/r61bt7JixQoGDhzI7373O44//vhY36Ns69ChA6NGjeLGG2+kT58+Fb9zAwcOrPg3+f6vWrWKCy64gDVr1vDNN9+k1dFYuHAho0ePZv369WzatIlevXpl78XsAdydm2++mTfffJO8vDw++eQTPvvsMwCaN29OUVERAF26dGHFihWsX7+eL7/8suJ4xUUXXcTLL79cY51nn32W8ePHs23bNtasWcPixYspLy+nRYsWFT+XgQMHMn78eABee+01pkyZUrFHVVZWxscff0zbtm13+TUGH+5ffPEFhxxyCHXq1OHxxx/n3Xff5S8LJyuzAAAFf0lEQVR/+Qv169fn5JNPpqCgAIBFixbRo0cPateO3pLS0tKKHzBQ0VsqLi7m9ttv32HYoHKd0CxevJi2bdtW+/4tWrSILl26VPRmSktLK3ZZS0tL6dKlS8W2iouLOeWUU1i0aBGdO3cmeZFbSUkJV199NRCFU5MmTTCzndZM/XktXryYbt26sW7durR7VXuTVq1aUVxczNSpU/nZz37GGWecAbDDnkny/z/5yU8YOXIkffv2ZcaMGYwZM6bG7Q8ZMoQXXniBwsJCHnvssYphhVA99dRTrF27luLiYurUqUN+fj5lZWUA7L///hXr1apVi6+//nqnw3u1a9emvLy8Yjm5neXLl3P33XczZ84cDj30UIYMGUJZWdlOt+XuPPfccxnpJAY/LLN8+XKaNGkCRLvxJ5xwAvXr1+e5555j1qxZdOjQoeK5jh07VnzfYYcdxgcffABEBwCffPJJCgsLady4MdOmTav4YS5YsAB336FOaJLj7dW9fwsXLtzhg7C0tLTivTzssMNYuHAhEAX7M888U7Gt1IOqqd9TUlJS8f/qalb+eZWUlHDCCScwceJEhg4dWtELC8Xq1aupW7cul1xyCaNGjao4cD9p0qSKf5N7Kxs2bKBp06YATJgwoWIbBx10EF9++WWV2//yyy9p3LgxW7durRhSC9mGDRs4/PDDqVOnDtOnT+ejjz7a6fqHHnooBx10ELNnzwZg4sSJFc/l5+czf/58ysvLWblyJe+++y4AGzdupF69ehxyyCF89tlnvPLKKwC0adOGZcuWsWLFCuBfP0OAXr16cf/991d8ALz33nu7/Rpj7bmne+piJrVp04bPP/+c9u3b8+CDDzJ06FAmT57MWWedRYsWLahXrx4QhUhy6ABg0KBBnH322XTr1o3jjz+e/Px8WrRowWWXXcb06dNp27YtBx54IO3bt+fJJ5/coc748eMrdt8yLd1TFzOppKSE7t27U1BQQL9+/b71/i1YsIAePXpUrL9w4cKKnvugQYM466yzKCoqonXr1jRo0IC2bdsyYcKEive7rKyMr7/+mkMPPRTYMegvvfTSamum/rxKSkro0aMHrVq14s477+THP/4xr7/+elb2pOI6dTHVggULuOGGG8jLy6NOnTo89NBD9O/fny1bttCjRw/Ky8t55plngOj0xQEDBtC0aVOOO+64ioP755xzDv379+fFF1/k/vvv32H7v/jFL+jRowfHHHMMHTp0qPZDIJPSOXUxWy6++GLOOeccunbtSlFRUcVxoJ155JFHuOKKK6hXrx6nnHIKhxxyCAAnnngizZs3p0OHDrRv357OnaOcSw7rFhQU0KJFC0488UQgGoJ88MEH6d27Nw0bNtzh9/iWW27huuuuo2PHjrg7+fn5aQ3/VMWyeTZBcXGxp+6S7002bdpE/fr1AbjrrrvYsGEDv/zlL3PcKpF/yc/PZ+7cuTRs2DDXTdknpGbC2LFjWbNmDffdd9932pa7c80119CyZcuKYybpKC4u5rbbbnsUuH7KlCkbq1on+GGZ3XXvvfdSUFBAUVERK1as4JZbbsl1k0Qkh/73f/+XoqIi2rdvz1tvvcXo0aN3e1sPP/wwRUVFFBQUsGHDBq666qoMtjSinruIyF5GPXcRkX2Uwl1EJEDZDndPPf9TRES+m/Ly8rSm1chquOfl5f3t008/3a6AFxH57srLy1mzZk15WVnZ5zWtm9Xz3MvLy89YuXLl26tXrz46lDk+RERyxd0pKytbN2HChD8AtYBqZ3jL6tkyAIl7/F0LtAbUhRcRyYwHp0yZUu0c41kPd4C+ffvWAZoC+9e0roiI7JQDX0yZMuWLna0US7iLiEi8dCqkiEiAFO4iIgFSuIuIBOj/AFaWceEXTXo0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rel_att_results = dict()\n",
    "for rel, atts in att_results.items():\n",
    "    if rel is None:\n",
    "        continue\n",
    "\n",
    "    rel_att_results[rel] = dict()\n",
    "    for i, mode in enumerate(atts):\n",
    "        for so in atts[mode]:\n",
    "            if (mode,so) not in mode2plotorder:\n",
    "                continue\n",
    "            \n",
    "            alphas, _, sents = atts[mode][so]\n",
    "\n",
    "            alphas_ = []\n",
    "            for alpha, sent in zip(alphas, sents):\n",
    "                sents_mask = np.expand_dims(np.array(sent == word2ix[rel], dtype=np.float), 1)\n",
    "                alphas_.append((alpha * sents_mask).sum(0))\n",
    "                            \n",
    "            a = np.array(alphas_)\n",
    "            \n",
    "            #a_min = a.min(0)\n",
    "            #a_max = a.max(0)\n",
    "            \n",
    "            # normalize the average attentions:\n",
    "            #a = (a - a_min) / (a_max - a_min)\n",
    "            a = a / np.expand_dims(a.sum(-1), -1)\n",
    "\n",
    "            a = a.mean(0)\n",
    "            rel_att_results[rel][mode] = a\n",
    "\n",
    "    \n",
    "\n",
    "for (mode,so) in mode2plotorder:\n",
    "    \n",
    "    limited_rels = ['right', 'left', 'above', 'over', 'under', 'below', 'on', 'in', 'near', 'side']\n",
    "    rels_a = sorted([\n",
    "        (rel, rel_att_results[rel][mode])\n",
    "        for rel in rel_att_results\n",
    "        if rel in limited_rels\n",
    "    ], key=lambda x: x[1][1])\n",
    "    \n",
    "    labels, a = list(zip(*rels_a))\n",
    "    a = np.array(a)\n",
    "\n",
    "    plt.title(mode2title[mode])\n",
    "    if a.shape[-1] == 4:\n",
    "        line_v2 = plt.bar(range(len(labels)), np.sum(a[:, :4], -1), label='$v_2$', color='slateblue')\n",
    "        line_v1 = plt.bar(range(len(labels)), np.sum(a[:, :3], -1), label='$v_1$', color='firebrick')\n",
    "        line_sp = plt.bar(range(len(labels)), np.sum(a[:, :2], -1), label='sp', color='green')\n",
    "        line_lm = plt.bar(range(len(labels)), np.sum(a[:, :1], -1), label='lm', color='gray')\n",
    "    else:\n",
    "        line_v2 = plt.bar(range(len(labels)), np.sum(a[:, :3], -1), label='$v_2$', color='slateblue')\n",
    "        line_v1 = plt.bar(range(len(labels)), np.sum(a[:, :2], -1), label='$v_1$', color='firebrick')\n",
    "        line_lm = plt.bar(range(len(labels)), np.sum(a[:, :1], -1), label='lm', color='gray')\n",
    "    \n",
    "    plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "    # Put a legend below current axis\n",
    "    plt.legend(\n",
    "        handles=(line_v2, line_v1, line_sp, line_lm),\n",
    "        labels=('$target$', '$landmark$', 'spatial', 'language'),\n",
    "        loc='lower center',\n",
    "        bbox_to_anchor=(0.49, -0.35),\n",
    "        fancybox=True, shadow=True, ncol=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# model file names\n",
    "new_models = {\n",
    "    'bbox-r': 'x_caption_model_bbox-r_6epochs.h5',\n",
    "    'implicit-r': 'x_caption_model_implicit-r_7epochs.h5',\n",
    "    'attention-r': 'x_caption_model_attention-r_11epochs.h5',\n",
    "}\n",
    "\n",
    "# this is how to load models\n",
    "new_models = {\n",
    "    mode: load_model(dir_path + filename)\n",
    "    for mode, filename in new_models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox-r': <keras.engine.training.Model at 0x7f74aa73d860>,\n",
       " 'implicit-r': <keras.engine.training.Model at 0x7f751e5382e8>,\n",
       " 'attention-r': <keras.engine.training.Model at 0x7f750547d390>}"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td + VisKE (rand)  : 0.9678\n",
      "td (rand)          : 0.9654\n",
      "td + mask (rand)   : 0.9116\n",
      "====== on ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.8312\n",
      "td + VisKE (rand)  (lnd-trg): 0.8312\n",
      "td (rand)          (trg-lnd): 0.8311\n",
      "td (rand)          (lnd-trg): 0.8311\n",
      "td + mask (rand)   (trg-lnd): 0.7771\n",
      "td + mask (rand)   (lnd-trg): 0.7776\n",
      "====== side ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0318\n",
      "td + VisKE (rand)  (lnd-trg): 1.0318\n",
      "td (rand)          (trg-lnd): 1.0058\n",
      "td (rand)          (lnd-trg): 1.0058\n",
      "td + mask (rand)   (trg-lnd): 0.9451\n",
      "td + mask (rand)   (lnd-trg): 0.9436\n",
      "====== in ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.8363\n",
      "td + VisKE (rand)  (lnd-trg): 0.8363\n",
      "td (rand)          (trg-lnd): 0.8565\n",
      "td (rand)          (lnd-trg): 0.8565\n",
      "td + mask (rand)   (trg-lnd): 0.8037\n",
      "td + mask (rand)   (lnd-trg): 0.8031\n",
      "====== with ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0008\n",
      "td + VisKE (rand)  (lnd-trg): 1.0008\n",
      "td (rand)          (trg-lnd): 0.9963\n",
      "td (rand)          (lnd-trg): 0.9963\n",
      "td + mask (rand)   (trg-lnd): 0.9397\n",
      "td + mask (rand)   (lnd-trg): 0.9400\n",
      "====== by ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0406\n",
      "td + VisKE (rand)  (lnd-trg): 1.0406\n",
      "td (rand)          (trg-lnd): 1.0481\n",
      "td (rand)          (lnd-trg): 1.0481\n",
      "td + mask (rand)   (trg-lnd): 1.0017\n",
      "td + mask (rand)   (lnd-trg): 1.0013\n",
      "====== near ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.9999\n",
      "td + VisKE (rand)  (lnd-trg): 0.9999\n",
      "td (rand)          (trg-lnd): 0.9975\n",
      "td (rand)          (lnd-trg): 0.9975\n",
      "td + mask (rand)   (trg-lnd): 0.9523\n",
      "td + mask (rand)   (lnd-trg): 0.9534\n",
      "====== behind ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.9335\n",
      "td + VisKE (rand)  (lnd-trg): 0.9335\n",
      "td (rand)          (trg-lnd): 0.9087\n",
      "td (rand)          (lnd-trg): 0.9087\n",
      "td + mask (rand)   (trg-lnd): 0.8988\n",
      "td + mask (rand)   (lnd-trg): 0.8975\n",
      "====== under ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.1226\n",
      "td + VisKE (rand)  (lnd-trg): 1.1226\n",
      "td (rand)          (trg-lnd): 1.0930\n",
      "td (rand)          (lnd-trg): 1.0930\n",
      "td + mask (rand)   (trg-lnd): 1.0460\n",
      "td + mask (rand)   (lnd-trg): 1.0460\n",
      "====== next ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.9798\n",
      "td + VisKE (rand)  (lnd-trg): 0.9798\n",
      "td (rand)          (trg-lnd): 0.9870\n",
      "td (rand)          (lnd-trg): 0.9870\n",
      "td + mask (rand)   (trg-lnd): 0.9392\n",
      "td + mask (rand)   (lnd-trg): 0.9389\n",
      "====== over ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.1511\n",
      "td + VisKE (rand)  (lnd-trg): 1.1511\n",
      "td (rand)          (trg-lnd): 1.1507\n",
      "td (rand)          (lnd-trg): 1.1507\n",
      "td + mask (rand)   (trg-lnd): 1.0785\n",
      "td + mask (rand)   (lnd-trg): 1.0784\n",
      "====== around ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.9925\n",
      "td + VisKE (rand)  (lnd-trg): 0.9925\n",
      "td (rand)          (trg-lnd): 0.9757\n",
      "td (rand)          (lnd-trg): 0.9757\n",
      "td + mask (rand)   (trg-lnd): 0.9446\n",
      "td + mask (rand)   (lnd-trg): 0.9433\n",
      "====== front ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.9576\n",
      "td + VisKE (rand)  (lnd-trg): 0.9576\n",
      "td (rand)          (trg-lnd): 0.9591\n",
      "td (rand)          (lnd-trg): 0.9591\n",
      "td + mask (rand)   (trg-lnd): 0.9084\n",
      "td + mask (rand)   (lnd-trg): 0.9083\n",
      "====== at ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0502\n",
      "td + VisKE (rand)  (lnd-trg): 1.0502\n",
      "td (rand)          (trg-lnd): 1.0469\n",
      "td (rand)          (lnd-trg): 1.0469\n",
      "td + mask (rand)   (trg-lnd): 0.9849\n",
      "td + mask (rand)   (lnd-trg): 0.9849\n",
      "====== above ======\n",
      "td + VisKE (rand)  (trg-lnd): 0.9535\n",
      "td + VisKE (rand)  (lnd-trg): 0.9535\n",
      "td (rand)          (trg-lnd): 0.9780\n",
      "td (rand)          (lnd-trg): 0.9780\n",
      "td + mask (rand)   (trg-lnd): 0.9038\n",
      "td + mask (rand)   (lnd-trg): 0.9037\n",
      "====== below ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2511\n",
      "td + VisKE (rand)  (lnd-trg): 1.2510\n",
      "td (rand)          (trg-lnd): 1.2741\n",
      "td (rand)          (lnd-trg): 1.2741\n",
      "td + mask (rand)   (trg-lnd): 1.2285\n",
      "td + mask (rand)   (lnd-trg): 1.2294\n",
      "====== against ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0387\n",
      "td + VisKE (rand)  (lnd-trg): 1.0387\n",
      "td (rand)          (trg-lnd): 1.0387\n",
      "td (rand)          (lnd-trg): 1.0387\n",
      "td + mask (rand)   (trg-lnd): 1.0000\n",
      "td + mask (rand)   (lnd-trg): 0.9996\n",
      "====== beside ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.1183\n",
      "td + VisKE (rand)  (lnd-trg): 1.1183\n",
      "td (rand)          (trg-lnd): 1.1027\n",
      "td (rand)          (lnd-trg): 1.1027\n",
      "td + mask (rand)   (trg-lnd): 1.0898\n",
      "td + mask (rand)   (lnd-trg): 1.0909\n",
      "====== inside ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.1792\n",
      "td + VisKE (rand)  (lnd-trg): 1.1792\n",
      "td (rand)          (trg-lnd): 1.1635\n",
      "td (rand)          (lnd-trg): 1.1635\n",
      "td + mask (rand)   (trg-lnd): 1.1353\n",
      "td + mask (rand)   (lnd-trg): 1.1341\n",
      "====== along ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0341\n",
      "td + VisKE (rand)  (lnd-trg): 1.0341\n",
      "td (rand)          (trg-lnd): 1.0565\n",
      "td (rand)          (lnd-trg): 1.0565\n",
      "td + mask (rand)   (trg-lnd): 1.0104\n",
      "td + mask (rand)   (lnd-trg): 1.0101\n",
      "====== underneath ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2178\n",
      "td + VisKE (rand)  (lnd-trg): 1.2178\n",
      "td (rand)          (trg-lnd): 1.2186\n",
      "td (rand)          (lnd-trg): 1.2186\n",
      "td + mask (rand)   (trg-lnd): 1.1263\n",
      "td + mask (rand)   (lnd-trg): 1.1274\n",
      "====== left ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.3481\n",
      "td + VisKE (rand)  (lnd-trg): 1.3481\n",
      "td (rand)          (trg-lnd): 1.3584\n",
      "td (rand)          (lnd-trg): 1.3584\n",
      "td + mask (rand)   (trg-lnd): 1.3196\n",
      "td + mask (rand)   (lnd-trg): 1.3211\n",
      "====== right ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.3923\n",
      "td + VisKE (rand)  (lnd-trg): 1.3923\n",
      "td (rand)          (trg-lnd): 1.3704\n",
      "td (rand)          (lnd-trg): 1.3704\n",
      "td + mask (rand)   (trg-lnd): 1.3160\n",
      "td + mask (rand)   (lnd-trg): 1.3156\n",
      "====== between ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2743\n",
      "td + VisKE (rand)  (lnd-trg): 1.2743\n",
      "td (rand)          (trg-lnd): 1.2872\n",
      "td (rand)          (lnd-trg): 1.2872\n",
      "td + mask (rand)   (trg-lnd): 1.2501\n",
      "td + mask (rand)   (lnd-trg): 1.2502\n",
      "====== to ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2160\n",
      "td + VisKE (rand)  (lnd-trg): 1.2160\n",
      "td (rand)          (trg-lnd): 1.1987\n",
      "td (rand)          (lnd-trg): 1.1987\n",
      "td + mask (rand)   (trg-lnd): 1.1817\n",
      "td + mask (rand)   (lnd-trg): 1.1811\n",
      "====== from ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2678\n",
      "td + VisKE (rand)  (lnd-trg): 1.2678\n",
      "td (rand)          (trg-lnd): 1.3008\n",
      "td (rand)          (lnd-trg): 1.3008\n",
      "td + mask (rand)   (trg-lnd): 1.2345\n",
      "td + mask (rand)   (lnd-trg): 1.2328\n",
      "====== through ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2371\n",
      "td + VisKE (rand)  (lnd-trg): 1.2371\n",
      "td (rand)          (trg-lnd): 1.2322\n",
      "td (rand)          (lnd-trg): 1.2322\n",
      "td + mask (rand)   (trg-lnd): 1.1673\n",
      "td + mask (rand)   (lnd-trg): 1.1662\n",
      "====== across ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2084\n",
      "td + VisKE (rand)  (lnd-trg): 1.2084\n",
      "td (rand)          (trg-lnd): 1.2036\n",
      "td (rand)          (lnd-trg): 1.2036\n",
      "td + mask (rand)   (trg-lnd): 1.1426\n",
      "td + mask (rand)   (lnd-trg): 1.1419\n",
      "====== outside ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.1685\n",
      "td + VisKE (rand)  (lnd-trg): 1.1685\n",
      "td (rand)          (trg-lnd): 1.1628\n",
      "td (rand)          (lnd-trg): 1.1628\n",
      "td + mask (rand)   (trg-lnd): 1.1324\n",
      "td + mask (rand)   (lnd-trg): 1.1299\n",
      "====== beneath ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.2477\n",
      "td + VisKE (rand)  (lnd-trg): 1.2477\n",
      "td (rand)          (trg-lnd): 1.2433\n",
      "td (rand)          (lnd-trg): 1.2433\n",
      "td + mask (rand)   (trg-lnd): 1.1876\n",
      "td + mask (rand)   (lnd-trg): 1.1877\n"
     ]
    }
   ],
   "source": [
    "new_results = dict()\n",
    "\n",
    "# the overall results are stored under 'None' index \n",
    "new_results[None] = dict()\n",
    "for mode, model in new_models.items():\n",
    "    new_results[None][mode] = dict()\n",
    "    for so in [(0,1)]:\n",
    "        out = model.evaluate_generator(\n",
    "            generator_features_description(\n",
    "                batch_size=batch_size,\n",
    "                split=(0,1.),\n",
    "                mode=mode, \n",
    "                spatial_order=so,\n",
    "                shuffle=False,\n",
    "                ),\n",
    "            steps=int(len(triplets)/batch_size)\n",
    "        )\n",
    "        new_results[None][mode] = out\n",
    "        print('{0:18} : {1:0.4f}'.format(mode2title[mode], out))\n",
    "\n",
    "# report the results for each bucket\n",
    "for rel, _triplets in buckets.items():\n",
    "    print('====== {} ======'.format(rel))\n",
    "    new_results[rel] = dict()\n",
    "    for mode, model in new_models.items():\n",
    "        new_results[rel][mode] = dict()\n",
    "        if mode in ['bbox', 'implicit', 'attention', 'bbox-r', 'implicit-r', 'attention-r']:\n",
    "            spatial_orders = [(0,1), (1,0)]\n",
    "        else: \n",
    "            spatial_orders = [None]\n",
    "        \n",
    "        for spatial_order in spatial_orders:\n",
    "            out = model.evaluate_generator(\n",
    "                generator_features_description(\n",
    "                    batch_size=bucket_size,\n",
    "                    split=(0,1.),\n",
    "                    mode=mode,\n",
    "                    all_data=_triplets,\n",
    "                    spatial_order=spatial_order,\n",
    "                ),\n",
    "                steps=int(len(_triplets)/bucket_size),\n",
    "            )\n",
    "            new_results[rel][mode][spatial_order] = out\n",
    "            print('{0:18} ({2}): {1:0.4f}'.format(\n",
    "                mode if mode not in mode2title else mode2title[mode],\n",
    "                out,\n",
    "                'lnd-trg' if spatial_order == (1,0) else 'trg-lnd'\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_att_models = dict()\n",
    "for mode, model in new_models.items():\n",
    "    if mode not in att_archs:\n",
    "        continue\n",
    "    inputs = model.inputs\n",
    "    new_att_models[mode] = Model(inputs, model.layers[-2].input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== on ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0000 0.0000 0.0000 0.0000\n",
      "td + VisKE (rand)  (lnd-trg): 1.0000 0.0000 0.0000 0.0000\n",
      "td (rand)          (trg-lnd): 0.9470 0.0223 0.0306\n",
      "td (rand)          (lnd-trg): 0.9475 0.0303 0.0221\n",
      "td + mask (rand)   (trg-lnd): 0.9538 0.0462 0.0000 0.0000\n",
      "td + mask (rand)   (lnd-trg): 0.9540 0.0460 0.0000 0.0000\n",
      "====== side ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0000 0.0000 0.0000 0.0000\n",
      "td + VisKE (rand)  (lnd-trg): 1.0000 0.0000 0.0000 0.0000\n",
      "td (rand)          (trg-lnd): 0.9430 0.0227 0.0343\n",
      "td (rand)          (lnd-trg): 0.9441 0.0334 0.0225\n",
      "td + mask (rand)   (trg-lnd): 0.9566 0.0434 0.0000 0.0000\n",
      "td + mask (rand)   (lnd-trg): 0.9569 0.0431 0.0000 0.0000\n",
      "====== in ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0000 0.0000 0.0000 0.0000\n",
      "td + VisKE (rand)  (lnd-trg): 1.0000 0.0000 0.0000 0.0000\n",
      "td (rand)          (trg-lnd): 0.9493 0.0233 0.0274\n",
      "td (rand)          (lnd-trg): 0.9502 0.0269 0.0230\n",
      "td + mask (rand)   (trg-lnd): 0.9675 0.0325 0.0000 0.0000\n",
      "td + mask (rand)   (lnd-trg): 0.9674 0.0326 0.0000 0.0000\n",
      "====== with ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0000 0.0000 0.0000 0.0000\n",
      "td + VisKE (rand)  (lnd-trg): 1.0000 0.0000 0.0000 0.0000\n",
      "td (rand)          (trg-lnd): 0.9491 0.0268 0.0241\n",
      "td (rand)          (lnd-trg): 0.9498 0.0244 0.0258\n",
      "td + mask (rand)   (trg-lnd): 0.9791 0.0209 0.0000 0.0000\n",
      "td + mask (rand)   (lnd-trg): 0.9793 0.0207 0.0000 0.0000\n",
      "====== by ======\n",
      "td + VisKE (rand)  (trg-lnd): 1.0000 0.0000 0.0000 0.0000\n",
      "td + VisKE (rand)  (lnd-trg): 1.0000 0.0000 0.0000 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-838-4e9af7a20c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 )),\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_triplets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbucket_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nix/store/6z0karx7hmqlbzpbyw9mixig6wn0klcz-python3-3.7.3-env/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_att_results = dict()\n",
    "\n",
    "for rel, _triplets in buckets.items():\n",
    "    print('====== {} ======'.format(rel))\n",
    "    \n",
    "    new_att_results[rel] = dict()\n",
    "    for mode, model in new_att_models.items():\n",
    "        new_att_results[rel][mode] = dict()\n",
    "        if mode in ['bbox', 'implicit', 'attention', 'bbox-r', 'implicit-r', 'attention-r']:\n",
    "            spatial_orders = [(0,1), (1,0)]\n",
    "        else: \n",
    "            spatial_orders = [None]\n",
    "        \n",
    "        for so in spatial_orders:\n",
    "            out = model.predict_generator(\n",
    "                generator_wraper(generator_features_description(\n",
    "                    batch_size=bucket_size, \n",
    "                    split=(0,1.), \n",
    "                    mode=mode, \n",
    "                    all_data=_triplets,\n",
    "                    spatial_order=so,\n",
    "                    shuffle=False,\n",
    "                )),\n",
    "                steps=int(len(_triplets)/bucket_size),\n",
    "            )\n",
    "            \n",
    "            sents = np.array([item2features(item)[-1][1:] for item in _triplets])\n",
    "            sents_mask = np.expand_dims(np.array(sents != 0, dtype=np.float), 2)\n",
    "\n",
    "            if len(out) == 4:\n",
    "                lm, sp, vs, alpha = out\n",
    "                lm_norms = np.expand_dims(np.linalg.norm(lm, axis=-1), 2)\n",
    "                vs_norm = np.repeat(np.expand_dims(np.linalg.norm(vs, axis=-1), 1), lm.shape[1], axis=1)\n",
    "                sp_norm = np.repeat(np.expand_dims(np.expand_dims(np.linalg.norm(sp, axis=-1), 1), 1), lm.shape[1], axis=1)\n",
    "                norms = np.concatenate([lm_norms, sp_norm, vs_norm, ], axis=2)\n",
    "                new_att_results[rel][mode][so] = [norms * alpha, alpha, sents]\n",
    "            else:\n",
    "                lm, vs, alpha = out\n",
    "                lm_norms = np.expand_dims(np.linalg.norm(lm, axis=-1), 2)\n",
    "                vs_norm = np.repeat(np.expand_dims(np.linalg.norm(vs, axis=-1), 1), lm.shape[1], axis=1)\n",
    "                norms = np.concatenate([lm_norms, vs_norm], axis=2)\n",
    "                new_att_results[rel][mode][so] = [norms * alpha, alpha, sents]\n",
    "                \n",
    "            print('{0:18} ({2}): {1}'.format(\n",
    "                mode if mode not in mode2title else mode2title[mode],\n",
    "                ' '.join(['{0:0.4f}'.format(f) for f in att_results[rel][mode][so][1].mean(0).mean(0)]),\n",
    "                'lnd-trg' if so == (1,0) else 'trg-lnd'\n",
    "            ))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_, a, s = att_results['on']['bbox-r'][(0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8.7291706e-01, 3.1413612e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.0665045e+00, 3.3373482e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.5884610e+00, 3.0190248e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.2712572e+00, 3.2284311e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.2732003e+00, 3.2285294e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.2749550e+00, 3.2286032e-09, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[8.2214403e-01, 3.1229943e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.8879023e+00, 3.0875644e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.5475278e+00, 3.1787826e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.3112054e+00, 3.2037690e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.3116608e+00, 3.2037444e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.3119342e+00, 3.2037200e-09, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[7.4736249e-01, 3.1308458e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.7919238e+00, 3.0555443e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.6374658e+00, 3.1059244e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.3123415e+00, 3.2312091e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.3146336e+00, 3.2312770e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.3160620e+00, 3.2313263e-09, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[7.3033315e-01, 3.1352496e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [2.3199320e+00, 3.0964364e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.8320588e+00, 3.0251579e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.2822149e+00, 3.2288006e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.2850065e+00, 3.2289356e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.2866991e+00, 3.2290590e-09, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[9.0575171e-01, 3.1613387e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.8084552e+00, 3.0568830e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [2.0887945e+00, 3.0594609e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.3057902e+00, 3.2204150e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.3092752e+00, 3.2205192e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.3120065e+00, 3.2205993e-09, 0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[9.4068199e-01, 3.1117404e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.6377195e+00, 3.0366498e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.4408522e+00, 2.9693965e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        ...,\n",
       "        [3.2851007e+00, 3.1851566e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.2880664e+00, 3.1852416e-09, 0.0000000e+00, 0.0000000e+00],\n",
       "        [3.2900717e+00, 3.1852900e-09, 0.0000000e+00, 0.0000000e+00]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
